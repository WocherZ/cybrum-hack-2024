# Хакатон Цифрум

Репозиторий решения команды AXIOM на хакатоне по предиктивной аналитике Цифрум.

# Задача

Постановка задачи: Разработать модель, которая способна генерировать текст на основе предоставленного начального текста и поставленной бизнес задачи.

Решение было сфокусированно на генерации маркетинговых текстов для размещения рекламы продуктов Росатома на различных площадках. Это особенно важно, так как помогает ускорить процесс создания контента и повысить разнообразие без необходимости значительных временных затрат.

# Команда: AXIOM
- Зворыгин Владимир Андреевич
- Миронов Андрей Михайлович
- Диков Александр Евгеньевич
- Садохин Алексей Александрович

# Структура проекта
- **_backend_**: fast api + развёртывание моделей с помощью [llama.cpp](https://github.com/ggerganov/llama.cpp)
- **_data_**: датасеты для обучения и валидации моделей
- **_frontend_**: [streamlit](https://streamlit.io/) приложение, позволяющее початиться с моделью
- **_models_**: модели, которые использовались для экспериментов и обучения
- **_notebooks_**: ноутбуки с экспериментами по задаче и тестированием разных моделей

# Идея решения

# Демо решения

# Разворачивание решения

### **Шаг 1: Клонирование репозитория или подготовка проекта**

Клонируйте репозитории Git:

```commandline
git clone https://github.com/WocherZ/cybrum-hack-2024.git
cd cybrum-hack-2024
```

### **Шаг 2: Создание виртуального окружения**

Рекомендуется использовать виртуальное окружение для изоляции зависимостей проекта.

```commandline
python3 -m venv venv
```

Активируйте виртуальное окружение:

- На Windows:
    ```commandline
    venv\Scripts\activate
    ```

- На macOS и Linux:
    ```commandline
    source venv/bin/activate
    ```

### **Шаг 3: Установка зависимостей из requirements.txt**

Убедитесь, что файл requirements.txt находится в корне вашего проекта. Для установки зависимостей выполните:

```commandline
pip install --upgrade pip
pip install -r requirements.txt
```

Обратите внимание что requirements.txt не содержит всех зависимостей, необходимых в ноутбуках из папки [notebooks](/notebooks/)

Это установит все необходимые библиотеки.

### **Шаг 4: Запуск Streamlit приложения**

После установки зависимостей и моделей запустите ваше Streamlit приложение, перейдя в папку [frontend](/frontend/):

```commandline
streamlit run main.py
```

После выполнения команды, Streamlit запустит локальный сервер, и в командной строке отобразится URL (обычно http://localhost:8501), по которому можно открыть приложение в браузере.

### **Шаг 6: Запуск Backend**

Запустите ваше бэкенд приложение на FastAPI, перейдя в папку [backend](/backend/):

```commandline
uvicorn main:app --reload
```

После выполнения команды запустится веб-сервер. Далее можно переходить к интерфейсу на Streamlit http://localhost:8501 и пользоваться разработанным приложением.
