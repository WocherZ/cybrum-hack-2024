{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "client = Client(\"Qwen/Qwen2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertising_sectors = {\n",
    "    'Образование': 5,\n",
    "    'IT индустрия': 5,\n",
    "    'Мероприятия': 5,\n",
    "    'Техника и электроника': 5,\n",
    "    'Еда': 5,\n",
    "    'Мода и стиль': 5,\n",
    "    'Здравоохранение': 5,\n",
    "    'Туризм и путешествия': 5,\n",
    "    'Строительство и недвижимость': 5,\n",
    "    'Финансы и инвестиции': 5,\n",
    "    'Развлечения и медиа': 5,\n",
    "    'Транспорт и логистика': 5,\n",
    "    'Экология и устойчивое развитие': 5,\n",
    "    'Спорт': 5,\n",
    "    'Фитнес': 5,\n",
    "    'Космическая индустрия': 5,\n",
    "    'Сельское хозяйство': 5,\n",
    "    'Автомобильная индустрия': 5,\n",
    "    'Ювелирные изделия': 5,\n",
    "    'Промышленное производство': 5,\n",
    "    'Право и юриспруденция': 5,\n",
    "    'Психология и саморазвитие': 5,\n",
    "    'Киберспорт': 5,\n",
    "    'Домашние животные': 5,\n",
    "    'Ремесла и хобби': 5,\n",
    "\n",
    "    'Добыча урана': 2,\n",
    "    'Производство ядерного топлива': 2,\n",
    "    'Производство электроэнергии': 2,\n",
    "    'Производство оборудования для атомной отрасли': 2,\n",
    "    'Строительство АЭС': 2,\n",
    "    'Атомный ледокольный флот': 2,\n",
    "    'Разработка и производство ядерных боеприпасов': 2,\n",
    "    'Дивизион химических волокон и композитов': 2,\n",
    "    'Научные исследования': 2,\n",
    "    'Ядерная безопасность': 2,\n",
    "    'Производство электромобилей': 2,\n",
    "\n",
    "    'Атом Майнд (Платформа промышленной цифровизации и предиктивной аналитики)': 4,\n",
    "    'Сарус (Система управления жизненным циклом изделий, PLM)': 4,\n",
    "    'Призма (Система управления дискретным производством, MES)': 4,\n",
    "    'Цифровой инжиниринг (Цифровые двойники, учебные тренажеры, модернизация предприятия)': 4,\n",
    "    'Дедал-Скаут (Система автоматизации полевого сервисного обслуживания)': 4,\n",
    "    'Almaz BI (Промышленная система анализа и визуализации данных, BI)': 4,\n",
    "    'Бизнес аналитика (Информационные дашборды для мониторинга ключевых показателей)': 4,\n",
    "    'Атом.РИТА (Low-code платформа роботизации бизнес-процессов, RPA)': 4,\n",
    "    'Атомбот (Готовые решения для автоматизации рутинных операций, AI, RPA)': 4,\n",
    "    'ЦОД (Colocation, Облачные услуги, сооружение ЦОД на заказ)': 4,\n",
    "    'Cloudate (Платформа управления облаками данных)': 4,\n",
    "    'Т-Ком (Линейка коммутаторов для построения корпоративных сетей)': 4,\n",
    "    'Атом.Порт (Автоматизированная миграция на Linux)': 4,\n",
    "    'Атом.Домен (Сервисы для управления импортонезависимой ИТ-инфраструктурой)': 4,\n",
    "    'Продукты Multi-D (Решения для управления сооружением инженерных объектов, BIM)': 4,\n",
    "    'Комплексная защищенность (Физическая, информационная и антитеррористическая безопасность)': 4,\n",
    "    'Результативная кибербезопасность (Индивидуальный проект по защите бизнеса)': 4,\n",
    "    'Безопасность инфраструктуры (Решения по защите сетевой инфраструктуры и устройств)': 4,\n",
    "    'Системная интеграция (Консалтинг, заказная разработка ПО, поддержка ИТ)': 4,\n",
    "    'Платформа Multi-D (Быстрая разработка на собственной low-code платформе)': 4,\n",
    "    'Логос (Модульное решение для инженерного анализа и моделирования, CAE)': 4,\n",
    "    'Атом.Око (программная роботизация, оптического распознавания текстов и платформ для создания бизнес-приложений)': 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_limitations_combinations(limitations, key_probabilities, N_sample):\n",
    "    limitations_set = []\n",
    "\n",
    "    for i in range(N_sample):\n",
    "        selected_items = {}\n",
    "\n",
    "        for key, probability in key_probabilities.items():\n",
    "            if random.random() < probability: \n",
    "                selected_items[key] = random.choice(limitations[key])\n",
    "        \n",
    "        limitations_set.append(selected_items)\n",
    "    \n",
    "    return limitations_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limitations = {\n",
    "    'text_size': ['Пиши кратко.', 'Не больше N символов.', 'Не превышай N слов.', 'Напиши несколько абзацев.', 'Максимально подробно.'],\n",
    "    'advertising_platform': ['Пост в социальной сети.', 'Таргетированная реклама.', 'Поисковая выдача.', 'Реклама на сайте.'],\n",
    "    'usage_emoji': ['Используй эмодзи при составлении рекламы.', 'Не используй эмодзи.'],\n",
    "    'mention_price': ['Укажи определённую цену товара/услуги.', 'Обязательно напиши цену для товара/услуги и используй её в рекламе.']\n",
    "}\n",
    "\n",
    "key_probabilities = {'text_size': 0.7, 'advertising_platform': 0.5, 'usage_emoji': 0.3, 'mention_price': 0.2}\n",
    "\n",
    "generate_limitations_combinations(limitations, key_probabilities, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "advertisement_limitations_sets = {}\n",
    "for advertisement, N_sample in advertising_sectors.items():\n",
    "    advertisement_limitations_sets[advertisement] = generate_limitations_combinations(limitations, key_probabilities, N_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_examples(client, area, limitations):\n",
    "    prompt_limitations = list(limitations)\n",
    "    random.shuffle(prompt_limitations)\n",
    "    system_prompt = '''Ты ассистент, который создан для генерации рекламных текстов. Используй только русский при ответах.'''\n",
    "    user_prompt = f'''Сгенерируй датасет для обучения ИИ помощника для генерации рекламы. В ответе укажи только 5 примеров и ничего больше.\n",
    "Все примеры делай для следующей сферы: {area}\n",
    "В запросе пользователя указывай следующие ограничения: {' '.join(prompt_limitations)}. В каждом сообщении пиши ограничения по-разному.\n",
    "Каждый пример из датасета пиши в JSON формате с новой строки:''' + '''{\"user\": \"Запрос пользователя о рекламе с учётом ограничений\", \"bot\": \"Рекламный текст товара в формате markdown\"}'''\n",
    "\n",
    "    # {\"id\": \"0\", \"messages\": [{\"role\": \"system\", \"content\": \"Ты ИИ ассистент.\"},{\"role\": \"user\", \"content\": \"Привет\"}, {\"role\": \"bot\", \"content\": \"Привет!\"}]}\n",
    "\n",
    "    result = client.predict(\n",
    "                    query=user_prompt,\n",
    "                    history=[],\n",
    "                    system=system_prompt,\n",
    "                    radio=\"72B\",        \n",
    "                    api_name=\"/model_chat\"\n",
    "            )\n",
    "    text_answer = result[1][0][-1]['text']\n",
    "    return text_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:58<00:00, 118.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_id = 0\n",
    "with open(\"validation_advertisment_dataset.jsonl\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for advertisment_area, limitations_list in tqdm(advertisement_limitations_sets.items()):\n",
    "        for limitation in limitations_list:\n",
    "            try:\n",
    "                text_dataset_examples = generate_dataset_examples(client, advertisment_area, limitation.values())\n",
    "                text_dataset_examples = \"\\n\".join(line for line in text_dataset_examples.splitlines() if line.strip())\n",
    "\n",
    "                for dataset_example in text_dataset_examples.split('\\n'):\n",
    "                    example = json.loads(dataset_example)\n",
    "                    user_prompt = example['user']\n",
    "                    bot_answer = example['bot']\n",
    "                    dataset_example_dialog = {\"id\": f\"{data_id}\", \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"Ты помощник по составлению рекламных текстов.\"},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt}, \n",
    "                        {\"role\": \"bot\", \"content\": bot_answer}\n",
    "                    ]}\n",
    "                    file.write(json.dumps(dataset_example_dialog, ensure_ascii=False))\n",
    "                    file.write(\"\\n\")\n",
    "                    data_id += 1\n",
    "                \n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(example)\n",
    "                #print(text_dataset_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Объединение нескльких jsonl файлов в один"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def merge_jsonl_files(input_files, output_file):\n",
    "    next_id = 0  \n",
    "    with open(output_file, 'w', encoding='utf-8') as out_f:\n",
    "        for file in input_files:\n",
    "            with open(file, 'r', encoding='utf-8') as in_f:\n",
    "                for line in in_f:\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        if 'id' in data and 'messages' in data:\n",
    "                            \n",
    "                            data['id'] = str(next_id)\n",
    "                            next_id += 1\n",
    "                           \n",
    "                            out_f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "                        else:\n",
    "                            print(f\"Пропущена строка: {line.strip()} (неверный формат)\")\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Ошибка при разборе строки: {line.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = ['datasets/general_topics_advertisment_dataset.jsonl', 'datasets/rosatom_general_advertisment_dataset.jsonl']\n",
    "output_file = 'dataset_advertisment.jsonl'\n",
    "merge_jsonl_files(input_files, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
