{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9YUKBU3SYD_C"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmSOl9LECQiS"
      },
      "source": [
        "### Load SFT framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PXGoj_Lyx0q",
        "outputId": "8dd0bee5-550c-40f6-dbc8-b4bdcc7fd053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'turbo-alignment'...\n",
            "remote: Enumerating objects: 4223, done.\u001b[K\n",
            "remote: Counting objects: 100% (1144/1144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (363/363), done.\u001b[K\n",
            "remote: Total 4223 (delta 831), reused 1048 (delta 774), pack-reused 3079 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4223/4223), 58.33 MiB | 13.75 MiB/s, done.\n",
            "Resolving deltas: 100% (2791/2791), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/turbo-llm/turbo-alignment.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DESRddXFggO",
        "outputId": "034e2089-3029-43cb-a36f-df492eff3e76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/turbo-alignment\n"
          ]
        }
      ],
      "source": [
        "%cd turbo-alignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZY2zFliCUva"
      },
      "source": [
        "### Load model from HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf7-1wlv1aoX",
        "outputId": "2c6cb556-34fd-42cb-a811-8d426cbb92c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
            "          with new flags from 'git clone'\n",
            "\n",
            "'git clone' has been updated in upstream Git to have comparable\n",
            "speeds to 'git lfs clone'.\n",
            "Cloning into 'Llama-3.2-3B-Instruct'...\n",
            "fatal: could not read Username for 'https://huggingface.co': No such device or address\n",
            "Error(s) during clone:\n",
            "git clone failed: exit status 128\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!git lfs clone https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct\n",
        "#!git lfs clone https://huggingface.co/Vikhrmodels/Vikhr-Llama-3.2-1B-Instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgplL7tYuvvC"
      },
      "source": [
        "### Test generation on base model and check architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VQSZ9iNIuvDT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import gc\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n",
        "\n",
        "def load_model_and_tokenizer(model_name, use_auth_token=False):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, device_map=\"auto\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "    return model, tokenizer\n",
        "\n",
        "def generate_text(model,\n",
        "                  tokenizer,\n",
        "                  prompt,\n",
        "                  temperature=1.0,\n",
        "                  max_length=100):\n",
        "    inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c23784dc80364e5498490e68ab806ae7",
            "7121cff530c34904b5c4f69a580f53ff",
            "02f0773fc3884e60a1d09bd88a5056b0",
            "1221439a485e4c148c0296576d29b0e5",
            "c2d0e7b2ae0c47a9902a1d89e4ab97b4",
            "54ffd753c73348338e8b7fb08b0e2946",
            "38aa7c5a2dbc41a6884b64561379ba5e",
            "e5cf0a2002c84f9bb8577aad3c849776",
            "de36691a6a6f43f4a40e3e5ba10fa818",
            "e9f18579d08a408eac5cf2e84a49fdb2",
            "f46fc9654fe449ab9e8199039ca406f2"
          ]
        },
        "id": "VM292NbOuz64",
        "outputId": "c562a57d-66ed-4483-d299-6d958a173703"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c23784dc80364e5498490e68ab806ae7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"Vikhr-Gemma-2B-instruct\"\n",
        "model, tokenizer = load_model_and_tokenizer(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2PzUJXNxZvC",
        "outputId": "7abefdf8-291f-4555-e35e-14a5de843386"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Gemma2ForCausalLM(\n",
              "  (model): Gemma2Model(\n",
              "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-25): 26 x Gemma2DecoderLayer(\n",
              "        (self_attn): Gemma2Attention(\n",
              "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
              "          (rotary_emb): Gemma2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Gemma2MLP(\n",
              "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
              "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
              "          (act_fn): PytorchGELUTanh()\n",
              "        )\n",
              "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_e0WOO9u06w",
        "outputId": "d05c5d60-3d7e-4bb9-fbd8-af6d544e9a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Напиши рекламу для Атом.Оконов\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Напиши рекламу для Атом.Око\"\n",
        "generated_text_rugpt3l = generate_text(model,\n",
        "                                       tokenizer,\n",
        "                                       prompt)\n",
        "\n",
        "print(f\"{generated_text_rugpt3l}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mZ73cP11u2aH"
      },
      "outputs": [],
      "source": [
        "clear_memory()\n",
        "\n",
        "del model\n",
        "del tokenizer\n",
        "\n",
        "torch.cuda.synchronize()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srUZkED1CXk7"
      },
      "source": [
        "### Set parameters and disable w&b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bNwaTuXDkQSa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTZS1AbICX-9"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcPZA47n58qr",
        "outputId": "3272cc55-fedb-4b62-b804-cb4cb082e2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: poetry in /usr/local/lib/python3.10/dist-packages (1.8.4)\n",
            "Requirement already satisfied: build<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.2.2.post1)\n",
            "Requirement already satisfied: cachecontrol<0.15.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.15.0,>=0.14.0->poetry) (0.14.1)\n",
            "Requirement already satisfied: cleo<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.1.0)\n",
            "Requirement already satisfied: crashtest<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.4.1)\n",
            "Requirement already satisfied: dulwich<0.22.0,>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.21.7)\n",
            "Requirement already satisfied: fastjsonschema<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.20.0)\n",
            "Requirement already satisfied: installer<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.7.0)\n",
            "Requirement already satisfied: keyring<25.0.0,>=24.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (24.3.1)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (24.2)\n",
            "Requirement already satisfied: pexpect<5.0.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (4.9.0)\n",
            "Requirement already satisfied: pkginfo<2.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.11.2)\n",
            "Requirement already satisfied: platformdirs<5,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (4.3.6)\n",
            "Requirement already satisfied: poetry-core==1.9.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.9.1)\n",
            "Requirement already satisfied: poetry-plugin-export<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.8.0)\n",
            "Requirement already satisfied: pyproject-hooks<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.2.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.26 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.0.0)\n",
            "Requirement already satisfied: shellingham<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from poetry) (1.5.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from poetry) (2.1.0)\n",
            "Requirement already satisfied: tomlkit<1.0.0,>=0.11.4 in /usr/local/lib/python3.10/dist-packages (from poetry) (0.13.2)\n",
            "Requirement already satisfied: trove-classifiers>=2022.5.19 in /usr/local/lib/python3.10/dist-packages (from poetry) (2024.10.21.16)\n",
            "Requirement already satisfied: virtualenv<21.0.0,>=20.26.6 in /usr/local/lib/python3.10/dist-packages (from poetry) (20.28.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from cachecontrol<0.15.0,>=0.14.0->cachecontrol[filecache]<0.15.0,>=0.14.0->poetry) (1.1.0)\n",
            "Requirement already satisfied: filelock>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from cachecontrol[filecache]<0.15.0,>=0.14.0->poetry) (3.16.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from cleo<3.0.0,>=2.1.0->poetry) (3.10.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from dulwich<0.22.0,>=0.21.2->poetry) (2.2.3)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.10/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.11.4 in /usr/local/lib/python3.10/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (8.5.0)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/lib/python3/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (3.3.1)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/lib/python3/dist-packages (from keyring<25.0.0,>=24.0.0->poetry) (0.7.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect<5.0.0,>=4.7.0->poetry) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.26->poetry) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.26->poetry) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.26->poetry) (2024.8.30)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv<21.0.0,>=20.26.6->poetry) (0.3.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.0.0->poetry) (3.21.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from jaraco.classes->keyring<25.0.0,>=24.0.0->poetry) (10.5.0)\n",
            "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
            "\n",
            "No dependencies to install or update\n",
            "\n",
            "\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mturbo-alignment\u001b[39m (\u001b[39;1m0.0.4\u001b[39;22m)\u001b[1G\u001b[2K\u001b[39;1mInstalling\u001b[39;22m the current project: \u001b[36mturbo-alignment\u001b[39m (\u001b[32m0.0.4\u001b[39m)\n"
          ]
        }
      ],
      "source": [
        "%pip install poetry\n",
        "!poetry install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ny0KmNRIBEY"
      },
      "outputs": [],
      "source": [
        "!poetry update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi2E36vaHSnw"
      },
      "outputs": [],
      "source": [
        "# Special for Google Colab\n",
        "%pip install -q peft==0.9 cached-path pydantic-settings loguru triton pytorchvideo datasets evaluate rouge_score clearml timm wandb vllm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ROoaX3JlWg"
      },
      "source": [
        "### Test base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPbj9nuj20A3",
        "outputId": "3add1c89-ca05-4bd7-81f5-43df86e86401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-11-26 12:13:27.632323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-26 12:13:27.653416: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-26 12:13:27.659608: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-26 12:13:27.674939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-26 12:13:28.879853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in BaseTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in ClassificationTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in DDPOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in DPOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in KTOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in MultimodalTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in RAGTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in RMTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in SftTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "tokenizer_config.json: 100% 54.5k/54.5k [00:00<00:00, 58.4MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 6.45MB/s]\n",
            "special_tokens_map.json: 100% 296/296 [00:00<00:00, 1.97MB/s]\n",
            "config.json: 100% 878/878 [00:00<00:00, 5.73MB/s]\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 71.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<01:57, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.97G [00:00<01:56, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<01:54, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<01:54, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.97G [00:01<01:55, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.97G [00:01<01:55, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:01<01:56, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.97G [00:01<01:55, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.97G [00:02<01:55, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.97G [00:02<01:54, 42.3MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.97G [00:02<01:55, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.97G [00:02<01:55, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.97G [00:03<02:01, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.97G [00:03<02:00, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.97G [00:03<01:58, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.97G [00:04<02:04, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.97G [00:04<02:01, 39.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.97G [00:04<01:58, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.97G [00:04<01:55, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.97G [00:05<01:54, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.97G [00:05<01:52, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.97G [00:05<01:52, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.97G [00:05<01:52, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.97G [00:06<01:53, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.97G [00:06<01:52, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.97G [00:06<01:53, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.97G [00:06<01:51, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.97G [00:07<01:50, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.97G [00:07<01:50, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.97G [00:07<01:49, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.97G [00:07<01:49, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.97G [00:08<01:48, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.97G [00:08<01:48, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:08<01:48, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.97G [00:08<01:50, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:09<01:52, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.97G [00:09<01:50, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:09<01:49, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.97G [00:09<01:50, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:10<01:52, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.97G [00:10<01:52, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.97G [00:10<01:51, 40.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.97G [00:10<01:51, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.97G [00:11<01:50, 40.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.97G [00:11<01:50, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:11<01:49, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.97G [00:11<01:52, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:12<01:52, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.97G [00:12<01:49, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:12<01:49, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.97G [00:12<01:48, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.97G [00:13<01:47, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.97G [00:13<01:45, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.97G [00:13<01:44, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.97G [00:13<01:43, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.97G [00:14<01:42, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.97G [00:14<01:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.97G [00:14<01:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.97G [00:14<01:41, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:15<01:41, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.97G [00:15<01:41, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:15<01:40, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.97G [00:15<01:41, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.97G [00:16<01:40, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.97G [00:16<01:39, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:16<01:39, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.97G [00:16<01:39, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.97G [00:17<01:39, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.97G [00:17<01:38, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:17<01:38, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.97G [00:17<01:38, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:18<01:38, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.97G [00:18<01:37, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:18<01:38, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.97G [00:18<01:38, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:19<01:37, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.97G [00:19<01:36, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:19<01:36, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.97G [00:19<01:37, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:20<01:38, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.97G [00:20<01:37, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:20<01:38, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.97G [00:20<01:37, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:21<01:39, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.97G [00:21<01:38, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:21<01:37, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.97G [00:21<01:37, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:22<01:37, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.97G [00:22<01:37, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:22<01:37, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.97G [00:22<01:36, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:23<01:36, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.97G [00:23<01:35, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:23<01:34, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.97G [00:23<01:34, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:24<01:33, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.97G [00:24<01:32, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:24<01:32, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.97G [00:24<01:34, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:25<01:34, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.97G [00:25<01:33, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:25<01:32, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:25<01:31, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:26<01:31, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.97G [00:26<01:30, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:26<01:30, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:26<01:30, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:27<01:30, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.97G [00:27<01:29, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.97G [00:27<01:28, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:27<01:28, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:28<01:29, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.97G [00:28<01:28, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.97G [00:28<01:28, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:28<01:28, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:29<01:27, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.97G [00:29<01:27, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:29<01:27, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.97G [00:29<01:27, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:30<01:27, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:30<01:26, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:30<01:26, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.97G [00:30<01:26, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:30<01:26, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.97G [00:31<01:26, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.97G [00:31<01:25, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.97G [00:31<01:25, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:31<01:25, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.97G [00:32<01:24, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:32<01:26, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.97G [00:32<01:26, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.97G [00:32<01:25, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:33<01:25, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.97G [00:33<01:24, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.97G [00:33<01:28, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.97G [00:34<01:34, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:34<01:30, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.97G [00:34<01:28, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:34<01:26, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.97G [00:35<01:26, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.97G [00:35<01:25, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:35<01:29, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.97G [00:35<01:27, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:36<01:25, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:36<01:24, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.97G [00:36<01:23, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.97G [00:36<01:22, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:37<01:21, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.97G [00:37<01:20, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:37<01:19, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:37<01:19, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:38<01:19, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:38<01:18, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.97G [00:38<01:20, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:38<01:20, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.97G [00:39<01:19, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:39<01:18, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.97G [00:39<01:21, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:39<01:19, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:40<01:18, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.97G [00:40<01:18, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.97G [00:40<01:19, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:40<01:18, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.97G [00:41<01:17, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.97G [00:41<01:16, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:41<01:16, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.97G [00:41<01:16, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.97G [00:42<01:15, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:42<01:15, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.97G [00:42<01:14, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.97G [00:42<01:14, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:43<01:14, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.97G [00:43<01:13, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.97G [00:43<01:14, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:43<01:13, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.97G [00:44<01:13, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.97G [00:44<01:12, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:44<01:12, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:44<01:12, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/4.97G [00:45<01:12, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:45<01:12, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.97G [00:45<01:11, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:45<01:11, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.97G [00:46<01:10, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:46<01:10, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.97G [00:46<01:10, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:46<01:10, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.97G [00:47<01:10, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.97G [00:47<01:10, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:47<01:09, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.97G [00:47<01:09, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.97G [00:48<01:09, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:48<01:08, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.97G [00:48<01:08, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:48<01:10, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.97G [00:49<01:09, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:49<01:08, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.97G [00:49<01:08, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:49<01:07, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.97G [00:50<01:07, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.97G [00:50<01:06, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:50<01:06, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.97G [00:50<01:06, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.97G [00:51<01:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:51<01:06, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.97G [00:51<01:07, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.97G [00:51<01:06, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.97G [00:52<01:07, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:52<01:06, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.97G [00:52<01:05, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.97G [00:52<01:05, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.97G [00:53<01:04, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:53<01:04, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.97G [00:53<01:03, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:53<01:03, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.26G/4.97G [00:54<01:03, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:54<01:03, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.97G [00:54<01:03, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.97G [00:54<01:03, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:55<01:04, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:55<01:04, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.97G [00:55<01:03, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:55<01:02, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.97G [00:56<01:03, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.97G [00:56<01:02, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:56<01:02, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.97G [00:56<01:01, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.97G [00:57<01:01, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:57<01:01, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.97G [00:57<01:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.97G [00:57<01:00, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.97G [00:58<01:00, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:58<00:59, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.97G [00:58<00:59, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.97G [00:58<00:59, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.97G [00:59<00:59, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [00:59<00:58, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.97G [00:59<00:58, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.97G [00:59<00:57, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.97G [00:59<00:57, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.97G [01:00<00:57, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [01:00<00:56, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.97G [01:00<00:56, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.97G [01:00<00:57, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [01:01<00:56, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.97G [01:01<00:56, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.97G [01:01<00:55, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.97G [01:01<00:55, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [01:02<00:55, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.97G [01:02<00:55, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.97G [01:02<00:54, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.97G [01:02<00:54, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.97G [01:03<00:53, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.97G [01:03<00:53, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.97G [01:03<00:53, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.97G [01:03<00:53, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.97G [01:04<00:53, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.97G [01:04<00:52, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.97G [01:04<00:52, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.97G [01:04<00:52, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.97G [01:05<00:51, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.97G [01:05<00:52, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.97G [01:05<00:52, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.97G [01:05<00:53, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [01:06<00:52, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.97G [01:06<00:51, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [01:06<00:51, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.97G [01:06<00:50, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.97G [01:07<00:51, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.97G [01:07<00:50, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.97G [01:07<00:50, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.97G [01:07<00:50, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.97G [01:08<00:50, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.97G [01:08<00:49, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.97G [01:08<00:49, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.97G [01:08<00:48, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [01:09<00:48, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.97G [01:09<00:48, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.97G [01:09<00:48, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.97G [01:09<00:48, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [01:10<00:48, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.96G/4.97G [01:10<00:48, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.97G [01:10<00:47, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [01:10<00:47, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.97G [01:11<00:47, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.97G [01:11<00:46, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.97G [01:11<00:46, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.97G [01:11<00:45, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.97G [01:12<00:45, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.97G [01:12<00:45, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.97G [01:12<00:44, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.97G [01:12<00:44, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [01:13<00:45, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.97G [01:13<00:45, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.97G [01:13<00:44, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.97G [01:13<00:45, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.97G [01:14<00:44, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.97G [01:14<00:44, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.97G [01:14<00:43, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.97G [01:14<00:43, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.97G [01:15<00:43, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.97G [01:15<00:43, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.97G [01:15<00:42, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.97G [01:15<00:42, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [01:16<00:42, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.97G [01:16<00:41, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.97G [01:16<00:41, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [01:16<00:41, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.97G [01:17<00:41, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [01:17<00:40, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.97G [01:17<00:40, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.97G [01:17<00:40, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.97G [01:18<00:40, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [01:18<00:40, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.97G [01:18<00:40, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [01:18<00:39, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.97G [01:19<00:39, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.97G [01:19<00:39, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.97G [01:19<00:45, 35.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.97G [01:20<00:43, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.97G [01:20<00:42, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.97G [01:20<00:40, 39.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.97G [01:20<00:39, 39.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.97G [01:21<00:41, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.97G [01:21<00:41, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.97G [01:21<00:39, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.97G [01:21<00:38, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.97G [01:22<00:37, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [01:22<00:36, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.97G [01:22<00:35, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.97G [01:22<00:35, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [01:23<00:37, 39.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.97G [01:23<00:36, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.97G [01:23<00:43, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.97G [01:24<00:44, 32.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.97G [01:24<00:40, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.97G [01:24<00:39, 36.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.97G [01:24<00:37, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.97G [01:25<00:36, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.97G [01:26<01:04, 21.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.97G [01:26<00:54, 25.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.97G [01:26<00:48, 28.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [01:26<00:44, 31.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.61G/4.97G [01:27<00:40, 33.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.97G [01:27<00:37, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.97G [01:27<00:36, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.97G [01:28<00:36, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.97G [01:28<00:34, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.97G [01:28<00:36, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.97G [01:29<00:42, 30.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.97G [01:29<00:39, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.97G [01:29<00:41, 30.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.97G [01:30<00:38, 32.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.97G [01:30<00:38, 32.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.97G [01:30<00:35, 35.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.97G [01:30<00:37, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.97G [01:31<00:35, 34.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.97G [01:31<00:33, 36.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.97G [01:31<00:34, 35.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.97G [01:32<00:34, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.97G [01:32<00:32, 36.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/4.97G [01:32<00:30, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [01:32<00:30, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.97G [01:33<00:29, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.97G [01:33<00:29, 39.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.97G [01:33<00:31, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.97G [01:34<00:31, 35.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.86G/4.97G [01:34<00:37, 29.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.97G [01:34<00:36, 30.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [01:35<00:33, 32.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.97G [01:35<00:31, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.90G/4.97G [01:35<00:32, 33.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [01:36<00:30, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.97G [01:36<00:28, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [01:36<00:27, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.97G [01:36<00:26, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.97G [01:37<00:30, 33.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.97G [01:37<00:28, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [01:37<00:26, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.97G [01:37<00:25, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.97G [01:38<00:25, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.97G [01:38<00:24, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.97G [01:38<00:25, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.97G [01:39<00:26, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [01:39<00:25, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.05G/4.97G [01:39<00:28, 32.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.97G [01:40<00:28, 32.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.97G [01:40<00:26, 33.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [01:41<00:40, 21.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.97G [01:41<00:36, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.97G [01:41<00:33, 25.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.97G [01:42<00:29, 29.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.97G [01:42<00:26, 32.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.97G [01:42<00:24, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [01:42<00:22, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.97G [01:43<00:22, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.97G [01:43<00:21, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.97G [01:43<00:20, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.97G [01:44<00:20, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/4.97G [01:44<00:20, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.97G [01:44<00:19, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.97G [01:44<00:18, 39.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.97G [01:45<00:18, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.97G [01:45<00:17, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.25G/4.97G [01:45<00:17, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.26G/4.97G [01:45<00:17, 40.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.97G [01:46<00:16, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.97G [01:46<00:16, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.97G [01:46<00:16, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.30G/4.97G [01:46<00:16, 39.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [01:47<00:16, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.97G [01:47<00:15, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.97G [01:47<00:15, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.97G [01:47<00:15, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.97G [01:48<00:14, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.97G [01:48<00:14, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [01:48<00:14, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.97G [01:49<00:27, 21.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.97G [01:49<00:17, 31.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.97G [01:50<00:16, 33.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/4.97G [01:50<00:15, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [01:50<00:14, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.97G [01:50<00:13, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.97G [01:51<00:12, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.97G [01:51<00:12, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.97G [01:51<00:11, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.97G [01:51<00:11, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.97G [01:52<00:11, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [01:52<00:11, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.97G [01:52<00:10, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.97G [01:52<00:10, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.97G [01:53<00:10, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.97G [01:53<00:09, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.97G [01:53<00:09, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.97G [01:53<00:09, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [01:54<00:09, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.97G [01:54<00:08, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.97G [01:54<00:08, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.97G [01:55<00:09, 35.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [01:55<00:09, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.97G [01:55<00:08, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.97G [01:55<00:08, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.66G/4.97G [01:56<00:09, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.97G [01:56<00:07, 40.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.97G [01:56<00:06, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.97G [01:56<00:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.70G/4.97G [01:57<00:06, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.97G [01:57<00:06, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.97G [01:57<00:05, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.97G [01:57<00:05, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/4.97G [01:58<00:05, 40.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [01:58<00:05, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.97G [01:58<00:04, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.97G [01:58<00:04, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.97G [01:59<00:04, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.97G [01:59<00:04, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.80G/4.97G [01:59<00:03, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [01:59<00:03, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.97G [02:00<00:03, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.97G [02:00<00:03, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.84G/4.97G [02:00<00:02, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [02:00<00:02, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.97G [02:01<00:02, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.97G [02:01<00:02, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.97G [02:01<00:01, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.97G [02:01<00:01, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.97G [02:02<00:01, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.97G [02:02<00:01, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.97G [02:02<00:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.97G [02:02<00:00, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.97G [02:03<00:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.97G [02:03<00:00, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [02:03<00:00, 40.2MB/s]\n",
            "Downloading shards:  50% 1/2 [02:03<02:03, 123.78s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/1.46G [00:00<00:34, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/1.46G [00:00<00:33, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 31.5M/1.46G [00:00<00:33, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 41.9M/1.46G [00:00<00:33, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 52.4M/1.46G [00:01<00:34, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 62.9M/1.46G [00:01<00:35, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 73.4M/1.46G [00:01<00:34, 40.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 83.9M/1.46G [00:02<00:33, 40.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 94.4M/1.46G [00:02<00:33, 40.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 105M/1.46G [00:02<00:32, 41.2MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 115M/1.46G [00:02<00:32, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 126M/1.46G [00:03<00:31, 41.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 136M/1.46G [00:03<00:31, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 147M/1.46G [00:03<00:31, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 157M/1.46G [00:03<00:31, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 168M/1.46G [00:04<00:31, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 178M/1.46G [00:04<00:32, 39.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 189M/1.46G [00:04<00:31, 39.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 199M/1.46G [00:04<00:30, 40.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 210M/1.46G [00:05<00:30, 41.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 220M/1.46G [00:05<00:30, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 231M/1.46G [00:05<00:29, 41.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 241M/1.46G [00:05<00:29, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 252M/1.46G [00:06<00:29, 41.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 262M/1.46G [00:06<00:28, 41.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 273M/1.46G [00:06<00:29, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 283M/1.46G [00:06<00:28, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 294M/1.46G [00:07<00:34, 33.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 304M/1.46G [00:07<00:32, 35.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 315M/1.46G [00:07<00:31, 36.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 325M/1.46G [00:08<00:29, 38.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 336M/1.46G [00:08<00:28, 39.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 346M/1.46G [00:08<00:27, 40.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 357M/1.46G [00:08<00:27, 40.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 367M/1.46G [00:09<00:26, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 377M/1.46G [00:09<00:25, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 388M/1.46G [00:09<00:26, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 398M/1.46G [00:09<00:25, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 409M/1.46G [00:10<00:25, 40.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 419M/1.46G [00:10<00:25, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 430M/1.46G [00:10<00:24, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 440M/1.46G [00:10<00:24, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 451M/1.46G [00:11<00:24, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 461M/1.46G [00:11<00:23, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 472M/1.46G [00:11<00:23, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 482M/1.46G [00:11<00:23, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 493M/1.46G [00:12<00:22, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 503M/1.46G [00:12<00:22, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 514M/1.46G [00:12<00:22, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 524M/1.46G [00:12<00:22, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 535M/1.46G [00:13<00:21, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 545M/1.46G [00:13<00:21, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 556M/1.46G [00:13<00:21, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 566M/1.46G [00:13<00:21, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 577M/1.46G [00:14<00:20, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 587M/1.46G [00:14<00:20, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 598M/1.46G [00:14<00:20, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 608M/1.46G [00:14<00:20, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 619M/1.46G [00:15<00:20, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 629M/1.46G [00:15<00:19, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 640M/1.46G [00:15<00:19, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 650M/1.46G [00:15<00:19, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 661M/1.46G [00:16<00:19, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 671M/1.46G [00:16<00:19, 40.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 682M/1.46G [00:16<00:18, 41.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 692M/1.46G [00:16<00:18, 40.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 703M/1.46G [00:17<00:19, 39.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 713M/1.46G [00:17<00:18, 40.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 724M/1.46G [00:17<00:17, 41.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 734M/1.46G [00:17<00:17, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 744M/1.46G [00:18<00:17, 39.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 755M/1.46G [00:18<00:17, 40.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 765M/1.46G [00:18<00:16, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 776M/1.46G [00:18<00:16, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 786M/1.46G [00:19<00:16, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 797M/1.46G [00:19<00:16, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 807M/1.46G [00:19<00:16, 39.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 818M/1.46G [00:19<00:16, 39.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 828M/1.46G [00:20<00:16, 39.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 839M/1.46G [00:20<00:15, 38.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 849M/1.46G [00:20<00:16, 37.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 860M/1.46G [00:21<00:15, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 870M/1.46G [00:21<00:20, 29.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 881M/1.46G [00:21<00:18, 31.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 891M/1.46G [00:22<00:16, 34.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 902M/1.46G [00:22<00:17, 32.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 912M/1.46G [00:22<00:15, 35.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 923M/1.46G [00:23<00:14, 37.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 933M/1.46G [00:23<00:13, 38.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 944M/1.46G [00:23<00:13, 39.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 954M/1.46G [00:23<00:12, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 965M/1.46G [00:24<00:12, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 975M/1.46G [00:24<00:12, 40.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 986M/1.46G [00:24<00:11, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 996M/1.46G [00:24<00:11, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.01G/1.46G [00:25<00:10, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.02G/1.46G [00:25<00:11, 39.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.03G/1.46G [00:25<00:10, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 1.04G/1.46G [00:25<00:10, 39.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 1.05G/1.46G [00:26<00:10, 37.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.06G/1.46G [00:26<00:12, 33.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.08G/1.46G [00:26<00:08, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.09G/1.46G [00:27<00:08, 41.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.10G/1.46G [00:27<00:08, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 1.11G/1.46G [00:27<00:08, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 1.12G/1.46G [00:27<00:07, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.13G/1.46G [00:28<00:07, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.14G/1.46G [00:28<00:07, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 1.15G/1.46G [00:28<00:07, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.16G/1.46G [00:28<00:06, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.17G/1.46G [00:29<00:06, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 1.18G/1.46G [00:29<00:06, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 1.20G/1.46G [00:29<00:06, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 1.21G/1.46G [00:29<00:05, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 1.22G/1.46G [00:30<00:05, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 1.23G/1.46G [00:30<00:05, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.24G/1.46G [00:30<00:05, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.25G/1.46G [00:30<00:05, 39.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 1.26G/1.46G [00:31<00:05, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 1.27G/1.46G [00:31<00:04, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.28G/1.46G [00:31<00:04, 39.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.29G/1.46G [00:32<00:04, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 1.30G/1.46G [00:32<00:04, 39.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 1.31G/1.46G [00:32<00:03, 40.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.32G/1.46G [00:32<00:03, 40.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.33G/1.46G [00:33<00:03, 41.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 1.34G/1.46G [00:33<00:02, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.35G/1.46G [00:33<00:02, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.36G/1.46G [00:33<00:02, 41.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 1.37G/1.46G [00:34<00:02, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 1.38G/1.46G [00:34<00:01, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.39G/1.46G [00:34<00:01, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.41G/1.46G [00:34<00:01, 41.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 1.42G/1.46G [00:35<00:01, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.43G/1.46G [00:35<00:00, 41.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.44G/1.46G [00:35<00:00, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 1.45G/1.46G [00:35<00:00, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:36<00:00, 40.4MB/s]\n",
            "Downloading shards: 100% 2/2 [02:40<00:00, 80.09s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 1.08MB/s]\n",
            "loader.py:26 [\u001b[1mINFO\u001b[0m] 2024-11-26T12:16:52+00:00 Loading dataset chat with settings:\n",
            "{'sources': [{'name': 'chat_test', 'system_prompt': None, 'sample_rate': 1.0, 'num_samples': None, 'records_path': Path('validation_advertisment_dataset.jsonl'), 'records_data': None, 'offset': None, 'n_rows': None}], 'dataset_type': <DatasetType.CHAT: 'chat'>, 'only_last_replica_loss': False, 'only_answer_loss': True, 'random_cut': False, 'keep_end': None, 'max_tokens_count': 500, 'prompt_template': {'prefix_template': ' ', 'suffix_template': ' ', 'role_tag_mapping': {'bot': '<bot>', 'user': '<user>', 'system': '<system>'}}, 'ignore_system_prompt': False}\n",
            "base.py:55 [\u001b[1mINFO\u001b[0m] 2024-11-26T12:16:52+00:00 Sampling dataset chat_test with sample rate: 1.0\n",
            "chat.py:270 [\u001b[1mINFO\u001b[0m] 2024-11-26T12:16:52+00:00 Tokenizing dataset chat_test\n",
            "chat.py:290 [\u001b[1mINFO\u001b[0m] 2024-11-26T12:16:52+00:00 Postprocessing tokenized data in chat_test\n",
            "base.py:48 [\u001b[1mINFO\u001b[0m] 2024-11-26T12:16:52+00:00 Sampled 20 records with offset None\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "CPU times: user 4.06 s, sys: 587 ms, total: 4.65 s\n",
            "Wall time: 10min 50s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python -m turbo_alignment inference_chat --inference_settings_path inference_test_setting.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFpnoBY4Jo_Z"
      },
      "source": [
        "### Fine-tuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yRbPa1dHf0G",
        "outputId": "a817315e-c6f2-47a1-9fb3-4e071b069d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 26 10:57:07 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0              27W /  70W |  10273MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKYqaVyH76QJ",
        "outputId": "69a2bc73-3178-4a50-c392-976045ffedce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-11-26 10:53:42.138805: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-26 10:53:42.176108: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-26 10:53:42.185979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-26 10:53:44.304014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in BaseTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in ClassificationTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in DDPOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in DPOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in KTOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in MultimodalTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in RAGTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in RMTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in SftTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "base.py:141 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Tokenizer is loaded!\n",
            "base.py:144 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Special tokens: []\n",
            "special_tokens_setter.py:23 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Model has bos_token_id = 2\n",
            "special_tokens_setter.py:32 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Model has eos_token_id = 1\n",
            "special_tokens_setter.py:45 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Model has pad_token_id = 3\n",
            "special_tokens_setter.py:60 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Model has unk_token_id = 3\n",
            "special_tokens_setter.py:66 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Skip adding sep_token_id\n",
            "special_tokens_setter.py:92 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Added custom special tokens: []\n",
            "base.py:149 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:53:52+00:00 Special tokens added!\n",
            "Loading checkpoint shards: 100% 3/3 [00:56<00:00, 18.68s/it]\n",
            "base.py:155 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:51+00:00 Model is loaded!\n",
            "loader.py:26 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:51+00:00 Loading dataset chat with settings:\n",
            "{'sources': [{'name': 'chat_test', 'system_prompt': None, 'sample_rate': 1.0, 'num_samples': None, 'records_path': Path('dataset_advertisment_v1.jsonl'), 'records_data': None, 'offset': None, 'n_rows': None}], 'dataset_type': <DatasetType.CHAT: 'chat'>, 'only_last_replica_loss': False, 'only_answer_loss': True, 'random_cut': False, 'keep_end': None, 'max_tokens_count': 4000, 'prompt_template': {'prefix_template': ' ', 'suffix_template': ' ', 'role_tag_mapping': {'bot': '<bot>', 'user': '<user>', 'system': '<system>'}}, 'ignore_system_prompt': False}\n",
            "base.py:55 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:51+00:00 Sampling dataset chat_test with sample rate: 1.0\n",
            "chat.py:270 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:51+00:00 Tokenizing dataset chat_test\n",
            "chat.py:290 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Postprocessing tokenized data in chat_test\n",
            "base.py:48 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Sampled 1102 records with offset None\n",
            "loader.py:26 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Loading dataset chat with settings:\n",
            "{'sources': [{'name': 'chat_test', 'system_prompt': None, 'sample_rate': 1.0, 'num_samples': None, 'records_path': Path('validation_advertisment_dataset.jsonl'), 'records_data': None, 'offset': None, 'n_rows': None}], 'dataset_type': <DatasetType.CHAT: 'chat'>, 'only_last_replica_loss': False, 'only_answer_loss': True, 'random_cut': False, 'keep_end': None, 'max_tokens_count': 4000, 'prompt_template': {'prefix_template': ' ', 'suffix_template': ' ', 'role_tag_mapping': {'bot': '<bot>', 'user': '<user>', 'system': '<system>'}}, 'ignore_system_prompt': False}\n",
            "base.py:55 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Sampling dataset chat_test with sample rate: 1.0\n",
            "chat.py:270 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Tokenizing dataset chat_test\n",
            "chat.py:290 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Postprocessing tokenized data in chat_test\n",
            "base.py:48 [\u001b[1mINFO\u001b[0m] 2024-11-26T10:54:53+00:00 Sampled 20 records with offset None\n",
            "/content/turbo-alignment/turbo_alignment/trainers/multigpu.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `MultiGPUCherryPicksTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/turbo-alignment/turbo_alignment/__main__.py\", line 3, in <module>\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 342, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 325, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 728, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 707, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/content/turbo-alignment/turbo_alignment/cli/train.py\", line 20, in train_sft_entrypoint\n",
            "    pipelines.TrainSFTStrategy().run(experiment_settings)\n",
            "  File \"/content/turbo-alignment/turbo_alignment/pipelines/train/base.py\", line 175, in run\n",
            "    self.trainer = self._get_trainer(\n",
            "  File \"/content/turbo-alignment/turbo_alignment/pipelines/train/sft.py\", line 77, in _get_trainer\n",
            "    return MultiGPUCherryPicksTrainer(\n",
            "  File \"/content/turbo-alignment/turbo_alignment/trainers/multigpu.py\", line 36, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/deprecation.py\", line 165, in wrapped_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 574, in __init__\n",
            "    self._move_model_to_device(model, args.device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 846, in _move_model_to_device\n",
            "    model = model.to(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1340, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 900, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 4 more times]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 927, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1326, in convert\n",
            "    return t.to(\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 42.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 17.06 MiB is free. Process 31956 has 10.03 GiB memory in use. Process 236844 has 4.70 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 120.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ],
      "source": [
        "!python -m turbo_alignment train_sft --experiment_settings_path lora_sft.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6cZpUozJTzG"
      },
      "outputs": [],
      "source": [
        "# Clear training logs\n",
        "%rm -r log_path/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjzEg_0rLJPm"
      },
      "source": [
        "### Test model with adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8QYmK7CE-tf",
        "outputId": "6d285f8a-964e-4506-bee6-f7d4a42e0f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-11-25 21:06:43.442998: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 21:06:43.462883: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 21:06:43.468861: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 21:06:44.663446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in BaseTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in ClassificationTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in DDPOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in DPOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in KTOTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in MultimodalTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in RAGTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in RMTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_settings\" in SftTrainExperimentSettings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/turbo-alignment/turbo_alignment/__main__.py\", line 3, in <module>\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 342, in __call__\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 325, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 728, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 197, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1688, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 707, in wrapper\n",
            "    return callback(**use_params)\n",
            "  File \"/content/turbo-alignment/turbo_alignment/cli/inference.py\", line 28, in infer_chat_entrypoint\n",
            "    pipelines.ChatInferenceStrategy().run(inference_settings)\n",
            "  File \"/content/turbo-alignment/turbo_alignment/pipelines/inference/base.py\", line 41, in run\n",
            "    for tokenizer, generator, filename, parameters_to_save in self._get_single_inference_settings(\n",
            "  File \"/content/turbo-alignment/turbo_alignment/pipelines/inference/chat.py\", line 30, in _get_single_inference_settings\n",
            "    import vllm\n",
            "ModuleNotFoundError: No module named 'vllm'\n",
            "CPU times: user 100 ms, sys: 8.04 ms, total: 108 ms\n",
            "Wall time: 13.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "!python -m turbo_alignment inference_chat --inference_settings_path lora_inference_test_setting.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr2k93x2FBV4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWiY32LBviVa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02f0773fc3884e60a1d09bd88a5056b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5cf0a2002c84f9bb8577aad3c849776",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de36691a6a6f43f4a40e3e5ba10fa818",
            "value": 3
          }
        },
        "1221439a485e4c148c0296576d29b0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f18579d08a408eac5cf2e84a49fdb2",
            "placeholder": "​",
            "style": "IPY_MODEL_f46fc9654fe449ab9e8199039ca406f2",
            "value": " 3/3 [00:01&lt;00:00,  2.38it/s]"
          }
        },
        "38aa7c5a2dbc41a6884b64561379ba5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54ffd753c73348338e8b7fb08b0e2946": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7121cff530c34904b5c4f69a580f53ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ffd753c73348338e8b7fb08b0e2946",
            "placeholder": "​",
            "style": "IPY_MODEL_38aa7c5a2dbc41a6884b64561379ba5e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c23784dc80364e5498490e68ab806ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7121cff530c34904b5c4f69a580f53ff",
              "IPY_MODEL_02f0773fc3884e60a1d09bd88a5056b0",
              "IPY_MODEL_1221439a485e4c148c0296576d29b0e5"
            ],
            "layout": "IPY_MODEL_c2d0e7b2ae0c47a9902a1d89e4ab97b4"
          }
        },
        "c2d0e7b2ae0c47a9902a1d89e4ab97b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de36691a6a6f43f4a40e3e5ba10fa818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5cf0a2002c84f9bb8577aad3c849776": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f18579d08a408eac5cf2e84a49fdb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f46fc9654fe449ab9e8199039ca406f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
